# llmcï¼šå‘ç²¾ç¡®é«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹å‹ç¼©è¿ˆè¿›

<img src="./imgs/llmc.png" alt="llmc" style="zoom:35%;" />

[![è®¸å¯è¯](https://img.shields.io/badge/è®¸å¯è¯-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![arXiv](https://img.shields.io/badge/LLMC-2405.06001-b31b1b)](https://arxiv.org/abs/2405.06001)
[![GitHub æ˜Ÿæ ‡](https://img.shields.io/github/stars/ModelTC/llmc.svg?style=social&label=Star&maxAge=60)](https://github.com/ModelTC/llmc)
[![Discord Banner](https://img.shields.io/discord/1139835312592392214?logo=discord&logoColor=white)](https://discord.gg/qZKUDfhm)
[![QQ](https://img.shields.io/badge/QQ-EB1923?logo=tencent-qq&logoColor=white)](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=I9IGPWWj8uuRXWH3_ELWjouf6gkIMgUl&authKey=GA3WbFAsm90ePJf%2FCbc7ZyXXq4ShQktlBaLxgqS5yuSPAsr3%2BDKMRdosUiLYoilO&noverify=0&group_code=526192592)
[![Doc](https://img.shields.io/badge/docs-English-99cc2)](https://llmc-en.readthedocs.io/en/latest/)
[![Doc](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡-99cc2)](https://llmc-zhcn.readthedocs.io/en/latest/)

**\[ [English](https://github.com/ModelTC/llmc?tab=readme-ov-file#llmc-towards-accurate-and-efficient-llm-compression) | ä¸­æ–‡ | [æ—¥æœ¬èª](README_ja.md) \]**

**llmc** æ˜¯ä¸€ä¸ªå³æ’å³ç”¨çš„å·¥å…·ï¼Œæ—¨åœ¨é€šè¿‡æœ€å…ˆè¿›çš„å‹ç¼©ç®—æ³•è¿›è¡Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å‹ç¼©ï¼Œä»¥æé«˜æ•ˆç‡å¹¶å‡å°æ¨¡å‹å¤§å°ï¼ŒåŒæ—¶ä¸ç‰ºç‰²æ€§èƒ½ã€‚

**è‹±æ–‡æ–‡æ¡£**åœ¨[è¿™é‡Œ](https://llmc-en.readthedocs.io/en/latest/).

**ä¸­æ–‡æ–‡æ¡£**åœ¨[è¿™é‡Œ](https://llmc-zhcn.readthedocs.io/en/latest/).

**docker hub**åœ¨[è¿™é‡Œ](https://hub.docker.com/r/llmcompression/llmc).

**ç¤¾åŒº**:

- [Discordç¾¤](https://discord.gg/qZKUDfhm)
- [QQç¾¤](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=I9IGPWWj8uuRXWH3_ELWjouf6gkIMgUl&authKey=GA3WbFAsm90ePJf%2FCbc7ZyXXq4ShQktlBaLxgqS5yuSPAsr3%2BDKMRdosUiLYoilO&noverify=0&group_code=526192592)

## æ–°é—»

- **2024å¹´9æœˆ23æ—¥:** ğŸ”¥ æˆ‘ä»¬ç°å·²æ”¯æŒå°† `LLMC` çš„ `çœŸå®é‡åŒ–` æ¨¡å‹å¯¼å‡ºè‡³ [SGLang](https://github.com/sgl-project/sglang)ã€[AutoAWQ](https://github.com/casper-hansen/AutoAWQ) å’Œ [MLC-LLM](https://github.com/mlc-ai/mlc-llm) ç­‰å…ˆè¿›æ¨ç†åç«¯ï¼Œä»¥è¿›è¡Œé‡åŒ–æ¨ç†éƒ¨ç½²ï¼Œä»è€Œ `å‡å°‘æ˜¾å­˜` å ç”¨å¹¶ `åŠ å¿«æ¨ç†é€Ÿåº¦`ã€‚è¯¦ç»†ä½¿ç”¨è¯·å‚è€ƒ [SGLang æ–‡æ¡£](https://llmc-zhcn.readthedocs.io/en/latest/backend/sglang.html)ã€[AutoAWQ æ–‡æ¡£](https://llmc-zhcn.readthedocs.io/en/latest/backend/autoawq.html) ä»¥åŠ [MLC-LLM æ–‡æ¡£](https://llmc-zhcn.readthedocs.io/en/latest/backend/mlcllm.html)ã€‚


- **2024å¹´9æœˆ3æ—¥:** ğŸš€ æˆ‘ä»¬æ”¯æŒäº†opencompassçš„ç²¾åº¦è¯„æµ‹ã€‚æ–‡æ¡£å‚è€ƒ[è¿™é‡Œ](https://llmc-zhcn.readthedocs.io/en/latest/advanced/model_test_v2.html)ã€‚æ¬¢è¿ä½¿ç”¨!

* **2024å¹´8æœˆ22æ—¥ï¼š** ğŸ”¥æˆ‘ä»¬æ”¯æŒåŒ…æ‹¬å½“å‰æœ€å…ˆè¿›çš„ [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)ï¼ˆè¯·å‚é˜… [æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨](#supported-model-list)ï¼‰åœ¨å†…çš„è®¸å¤šå°å‹è¯­è¨€æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡ä¿®æ”¹åçš„[lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) ğŸ¤— æ”¯æŒä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°ã€‚å…·ä½“æ¥è¯´ï¼Œäººä»¬å¯ä»¥é¦–å…ˆä½¿ç”¨`save_trans`æ¨¡å¼ï¼ˆè¯·å‚é˜… [é…ç½®](#é…ç½®) ä¸­çš„ `save` éƒ¨åˆ†ï¼‰æ¥ä¿å­˜ä¿®æ”¹åçš„æ¨¡å‹æƒé‡ã€‚è·å–è½¬æ¢åçš„æ¨¡å‹åï¼Œå¯ä»¥ç›´æ¥å‚è€ƒ  [run_lm_eval.sh](scripts/run_lm_eval.sh)æ¥è¯„ä¼°é‡åŒ–æ¨¡å‹ã€‚æ›´å¤šè¯¦æƒ…å¯åœ¨[è¿™é‡Œ](https://llmc-zhcn.readthedocs.io/en/latest/advanced/model_test.html#id2)æ‰¾åˆ°ã€‚

* **2024 å¹´ 7 æœˆ 23 æ—¥ï¼š** ğŸºğŸºğŸº æˆ‘ä»¬å‘å¸ƒäº†å…¨æ–°ç‰ˆæœ¬çš„åŸºå‡†è®ºæ–‡ï¼š

  [**LLMCï¼šä½¿ç”¨å¤šåŠŸèƒ½å‹ç¼©å·¥å…·åŒ…å¯¹å¤§å‹è¯­è¨€æ¨¡å‹é‡åŒ–è¿›è¡ŒåŸºå‡†æµ‹è¯•**](https://arxiv.org/abs/2405.06001v2)ã€‚

  [Ruihao Gong\*](https://xhplus.github.io/), [Yang Yong\*](https://github.com/helloyongyang), [Shiqiao Gu\*](https://github.com/gushiqiao), [Yushi Huang\*](https://github.com/Harahan), [Chengtao Lv](https://scholar.google.com/citations?user=r8vseSUAAAAJ&hl=en), [Yunchen Zhang](https://scholar.google.com/citations?user=glkWFyUAAAAJ&hl=en), [Xianglong LiuğŸ“§](https://xlliu-beihang.github.io/), [Dacheng Tao](https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=en)

  (\* è¡¨ç¤ºåŒç­‰è´¡çŒ®ï¼ŒğŸ“§ è¡¨ç¤ºé€šè®¯ä½œè€…ã€‚)

  <div align=center>
  <img src="./imgs/K.png" alt="comp" width="800" />
  </div>

  æˆ‘ä»¬ä¸å…³æ³¨æœ€ä½³å®è·µï¼Œè€Œæ˜¯è€ƒè™‘æ ¡å‡†æ•°æ®ã€ç®—æ³•å’Œæ•°æ®æ ¼å¼ï¼Œä»¥æ¨¡å—åŒ–å’Œå…¬å¹³çš„æ–¹å¼å¯¹ LLM é‡åŒ–è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚é€šè¿‡è¯¦ç»†çš„è§‚å¯Ÿå’Œåˆ†æï¼Œæˆ‘ä»¬ä¸ºä¸åŒé…ç½®ä¸‹çš„æ€§èƒ½å’Œæ–¹æ³•æ”¹è¿›æä¾›äº†å„ç§ç±»å‹çš„æ–°ç‚¹ã€‚å€ŸåŠ©å¼ºå¤§çš„å·¥å…·åŒ… LLMC å’Œå…¨é¢çš„è§è§£ï¼Œæœªæ¥çš„ LLM ç ”ç©¶äººå‘˜å¯ä»¥æœ‰æ•ˆåœ°å°†åˆé€‚çš„ç®—æ³•å’Œä½ä½æ ¼å¼é›†æˆåˆ°ä»–ä»¬çš„åº”ç”¨ä¸­ï¼Œä»è€Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹çš„å‹ç¼©å˜å¾—æ°‘ä¸»åŒ–ã€‚

* **2024å¹´7æœˆ16å·ï¼š** ğŸ”¥æˆ‘ä»¬ç°åœ¨å·²ç»æ”¯æŒäº†å¤§æ¨¡å‹ç¨€ç–ç®—æ³•Wanda/Naive(Magnitude)å’Œå±‚é—´æ··åˆbité‡åŒ–!

* **2024å¹´7æœˆ14å·ï¼š** ğŸ”¥æˆ‘ä»¬ç°åœ¨å·²ç»æ”¯æŒäº†æ—‹è½¬ç±»é‡åŒ–ç®—æ³•QuaRot!

* **2024å¹´7æœˆ4æ—¥:** ğŸ“± æˆ‘ä»¬æä¾›äº†å…¬å¼€çš„è®¨è®ºæ¸ é“. å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œå¯ä»¥åŠ å…¥æˆ‘ä»¬çš„ç¤¾åŒº:

  - [Discordç¾¤](https://discord.gg/qZKUDfhm)
  - [QQç¾¤](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=I9IGPWWj8uuRXWH3_ELWjouf6gkIMgUl&authKey=GA3WbFAsm90ePJf%2FCbc7ZyXXq4ShQktlBaLxgqS5yuSPAsr3%2BDKMRdosUiLYoilO&noverify=0&group_code=526192592)

* **2024å¹´5æœˆ13æ—¥:** ğŸºğŸºğŸº æˆ‘ä»¬å‘å¸ƒäº†é‡åŒ–åŸºå‡†è®ºæ–‡ï¼š

  [**LLM-QBenchï¼šå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒåé‡åŒ–çš„æœ€ä½³å®è·µåŸºå‡†**](https://arxiv.org/abs/2405.06001).

  [Ruihao Gong\*](https://xhplus.github.io/), [Yang Yong\*](https://github.com/helloyongyang), [Shiqiao Gu\*](https://github.com/gushiqiao), [Yushi Huang\*](https://github.com/Harahan), [Yunchen Zhang](https://scholar.google.com/citations?user=glkWFyUAAAAJ&hl=en), [Xianglong LiuğŸ“§](https://xlliu-beihang.github.io/), [Dacheng Tao](https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=en)

  (\* è¡¨ç¤ºå…±åŒç¬¬ä¸€ä½œè€…, ğŸ“§ è¡¨ç¤ºé€šè®¯ä½œè€….)

  <div align=center>
   <img src="./imgs/best_practice.png" alt="comp" width="800" />
  </div>

  æˆ‘ä»¬æ¨¡å—åŒ–å¹¶å…¬æ­£åœ°åŸºå‡†æµ‹è¯•äº†é‡åŒ–æŠ€æœ¯ï¼Œè€ƒè™‘åˆ°æ ¡å‡†æˆæœ¬ã€æ¨ç†æ•ˆç‡å’Œé‡åŒ–ç²¾åº¦ã€‚åœ¨å¤šç§æ¨¡å‹å’Œæ•°æ®é›†ä¸Šè¿›è¡Œçš„è¿‘ 600 é¡¹å®éªŒæä¾›äº†ä¸‰ä¸ªæ´è§ï¼š
  å…³äºæ ¡å‡†æ•°æ®ã€ç®—æ³•æµç¨‹å’Œé‡åŒ–é…ç½®é€‰æ‹©ã€‚åŸºäºè¿™äº›æ´è§ï¼Œè®¾è®¡äº†ä¸€ä¸ªæœ€ä½³çš„å¤§å‹è¯­è¨€æ¨¡å‹ PTQ æµç¨‹ï¼Œå®ç°äº†åœ¨å„ç§åœºæ™¯ä¸‹æœ€ä½³çš„ç²¾ç¡®åº¦å’Œæ•ˆç‡æ€§èƒ½å¹³è¡¡ã€‚

* **2024å¹´3æœˆ7æ—¥:** ğŸš€ æˆ‘ä»¬å‘å¸ƒäº†å¼ºå¤§ä¸”é«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹å‹ç¼©å·¥å…·çš„é‡åŒ–éƒ¨åˆ†ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„åŸºå‡†è®ºæ–‡å³å°†å‘å¸ƒğŸ˜Šã€‚

## çªå‡ºç‰¹æ€§

- é‡åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¦‚ Llama2-70Bã€OPT-175Bï¼Œå¹¶åœ¨ä»…ä¸€ä¸ª A100/H100/H800 GPUä¸Šè¯„ä¼°å…¶ PPLğŸ’¥ã€‚
- ä¸ºç”¨æˆ·æä¾›é€‰æ‹©çš„æœ€æ–°çš„[ä¸åŸè®ºæ–‡ä»£ç ä»“åº“ç²¾åº¦å¯¹é½](benchmark/align.md)çš„å‹ç¼©ç®—æ³•ï¼Œå¹¶ä¸”ç”¨æˆ·å¯ä»¥åœ¨ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä¸Šä¾æ¬¡ä½¿ç”¨å¤šä¸ªç®—æ³•ğŸ’¥ã€‚
- ç”±æˆ‘ä»¬å·¥å…·é€šè¿‡ç‰¹å®šå‹ç¼©ç®—æ³•å¯¼å‡ºçš„è½¬æ¢æ¨¡å‹ï¼ˆ`save_trans`æ¨¡å¼åœ¨`quant`éƒ¨åˆ†çš„[é…ç½®](#é…ç½®)ï¼‰å¯ä»¥é€šè¿‡å¤šä¸ªåç«¯è¿›è¡Œç®€å•é‡åŒ–ï¼Œå¾—åˆ°ç»è¿‡ç‰¹å®šå‹ç¼©ç®—æ³•ä¼˜åŒ–çš„æ¨¡å‹ï¼Œç›¸åº”çš„åç«¯å¯ä»¥è¿›è¡Œæ¨æ–­ğŸ’¥ã€‚
- æˆ‘ä»¬çš„å‹ç¼©æ¨¡å‹ï¼ˆ`save_lightllm`æ¨¡å¼åœ¨`quant`éƒ¨åˆ†çš„\[é…ç½®\](#é…ç½®)ï¼‰å…·æœ‰è¾ƒä½çš„å†…å­˜å ç”¨ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡[Lightllm](https://github.com/ModelTC/lightllm)è¿›è¡Œæ¨æ–­ğŸ’¥ã€‚

## ä½¿ç”¨æ–¹å¼

1. å…‹éš†æ­¤ä»“åº“å¹¶å®‰è£…åŒ…ï¼š

   ```shell
   # å®‰è£…åŒ…
   cd llmc
   pip install -r requirements.txt
   ```

2. å‡†å¤‡æ¨¡å‹å’Œæ•°æ®ã€‚

   ```shell
   # åœ¨ä»huggingfaceä¸‹è½½LLMåï¼ŒæŒ‰ä»¥ä¸‹æ–¹å¼å‡†å¤‡æ ¡å‡†å’Œè¯„ä¼°æ•°æ®ï¼š
   cd tools
   python download_calib_dataset.py --save_path [æ ¡å‡†æ•°æ®è·¯å¾„]
   python download_eval_dataset.py --save_path [è¯„ä¼°æ•°æ®è·¯å¾„]
   ```

3. é€‰æ‹©ä¸€ä¸ªç®—æ³•æ¥é‡åŒ–ä½ çš„æ¨¡å‹ï¼š

   ```shell
   # è¿™æ˜¯ä¸€ä¸ªå…³äº Awq çš„ä¾‹å­ï¼š
   cd scripts
   # ä¿®æ”¹ bash æ–‡ä»¶ä¸­çš„ llmc è·¯å¾„ï¼Œ``llmc_path``ã€‚ä½ ä¹Ÿå¯ä»¥é€‰æ‹©``llmc/configs/quantization/Awq/``ä¸­çš„ä¸€ä¸ªé…ç½®æ¥é‡åŒ–ä½ çš„æ¨¡å‹ï¼Œæˆ–è€…é€šè¿‡æ›´æ”¹``--config``å‚æ•°åœ¨ run_awq_llama.sh ä¸­ä½¿ç”¨æˆ‘ä»¬æä¾›çš„é…ç½®ã€‚
   bash run_awq_llama.sh
   ```

## é…ç½®

ä¸ºäº†å¸®åŠ©ç”¨æˆ·è®¾è®¡ä»–ä»¬çš„é…ç½®ï¼Œæˆ‘ä»¬ç°åœ¨è§£é‡Šæˆ‘ä»¬åœ¨`llmc/configs/`ä¸‹æä¾›çš„æ‰€æœ‰é…ç½®ä¸­çš„ä¸€äº›é€šç”¨é…ç½®ï¼š

- `model`:

  ```yaml
  model:
      # ç”¨``llmc/models/*.py``ä¸­çš„ç±»åæ›¿æ¢ã€‚
      type: Llama
      # ç”¨ä½ çš„æ¨¡å‹è·¯å¾„æ›¿æ¢ã€‚
      path: model path
      torch_dtype: auto
  ```

- `calib`:

  ```yaml
  # æ³¨æ„ï¼šä¸€äº›ç®—æ³•ä¸éœ€è¦``calib``ï¼Œå¦‚ naive... æ‰€ä»¥ï¼Œä½ å¯ä»¥ç§»é™¤è¿™éƒ¨åˆ†ã€‚
  calib:
      # ç”¨ä¹‹å‰ä¸‹è½½çš„æ ¡å‡†æ•°æ®åç§°æ›¿æ¢ï¼Œä¾‹å¦‚ï¼Œpilevalã€c4ã€wikitext2 æˆ– ptbã€‚
      name: pileval
      download: False
      # ç”¨ä¹‹å‰ä¸‹è½½çš„æŸä¸ªæ ¡å‡†æ•°æ®çš„è·¯å¾„æ›¿æ¢ï¼Œä¾‹å¦‚ï¼Œpilevalã€c4ã€wikitext2 æˆ– ptbã€‚
      path: calib data path
      n_samples: 128
      bs: -1
      seq_len: 512
      # ç”¨``llmc/data/dataset/specified_preproc.py``ä¸­çš„å‡½æ•°åç§°æ›¿æ¢ã€‚
      preproc: general
      seed: *seed
  ```

- `eval`:

  ```yaml
  # å¦‚æœä½ æƒ³è¯„ä¼°ä½ çš„é¢„è®­ç»ƒ/è½¬æ¢/å‡é‡åŒ–æ¨¡å‹çš„ PPLã€‚
  eval:
      # ä½ å¯ä»¥è¯„ä¼°é¢„è®­ç»ƒã€è½¬æ¢ã€å‡é‡åŒ–æ¨¡å‹ï¼Œå¹¶è®¾ç½®ä½ æƒ³è¦è¯„ä¼°çš„ä½ç½®ã€‚
      eval_pos: [pretrain, transformed, fake_quant]
      # ç”¨ä¹‹å‰ä¸‹è½½çš„è¯„ä¼°æ•°æ®çš„åç§°æ›¿æ¢ï¼Œä¾‹å¦‚ï¼Œc4ã€wikitext2ã€ptb æˆ– [c4, wikitext2]ã€‚
      name: wikitext2
      download: False
      path: eval data path
      # å¯¹äº 70B æ¨¡å‹è¯„ä¼°ï¼Œbs å¯ä»¥è®¾ç½®ä¸º 20ï¼Œå¹¶ä¸”å¯ä»¥å°† inference_per_block è®¾ç½®ä¸º Trueã€‚
      # å¯¹äº 7B / 13B æ¨¡å‹è¯„ä¼°ï¼Œbs å¯ä»¥è®¾ç½®ä¸º 1ï¼Œå¹¶ä¸”å¯ä»¥å°† inference_per_block è®¾ç½®ä¸º Falseã€‚
      bs: 1
      inference_per_block: False
      seq_len: 2048
  ```

- `save`:

  ```yaml
  save:
      # å¦‚æœ``save_trans``ä¸º Trueï¼Œè¿™æ„å‘³ç€ä½ æƒ³è¦å¯¼å‡ºè½¬æ¢æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œå‚æ•°ä¿®æ”¹çš„æ¨¡å‹ï¼Œå…¶æ€§èƒ½å’Œç»“æ„ä¸åŸå§‹æ¨¡å‹ç›¸åŒï¼Œç”¨æˆ·å¯ä»¥å¯¹è½¬æ¢æ¨¡å‹è¿›è¡Œç®€å•é‡åŒ–ï¼Œä»¥è·å¾—ä¸ç‰¹å®šç®—æ³•é‡åŒ–æ¨¡å‹ç›¸åŒçš„æ€§èƒ½ã€‚
      save_trans: False
      # å¦‚æœ``save_lightllm`` æˆ–è€… ``save_trtllm`` ä¸º Trueï¼Œè¿™æ„å‘³ç€ä½ æƒ³è¦å¯¼å‡ºçœŸå®çš„é‡åŒ–æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œä½ä½æƒé‡å’Œæƒé‡åŠæ¿€æ´»é‡åŒ–å‚æ•°ã€‚
      save_lightllm: False
      # å¦‚æœ``save_fake``ä¸º Trueï¼Œæ„å‘³ç€ä½ æƒ³è¦å¯¼å‡ºå‡é‡åŒ–æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œå»é‡åŒ–çš„æƒé‡å’Œæ¿€æ´»é‡åŒ–å‚æ•°ã€‚
      save_fake: False
      save_path: ./save

  ```

- `quant`:

  ```yaml
  quant:
      # ç”¨``llmc/compression/quantization/*.py``ä¸­çš„ç±»åæ›¿æ¢ã€‚
      method: OmniQuant
      # ä»…æƒé‡é‡åŒ–æ²¡æœ‰``act``éƒ¨åˆ†ã€‚
      weight:
          bit: 8
          symmetric: True
          # é‡åŒ–ç²’åº¦ï¼šper_channel, per_tensor, per_headï¼ˆä¸æ¨èï¼‰ã€‚
          granularity: per_channel
          group_size: -1
          # æ ¡å‡†ç®—æ³•ï¼šlearnble, mse, ä»¥åŠ minmaxï¼ˆé»˜è®¤ï¼‰ã€‚
          calib_algo: learnable
          # ä½¿ç”¨ç›´é€šä¼°è®¡ï¼ˆStright-Through Estimationï¼‰ï¼Œè¿™å¯¹äºå¯å­¦ä¹ çš„æ ¡å‡†ç®—æ³•æ˜¯å¿…éœ€çš„ã€‚
          ste: True
      act:
          bit: 8
          symmetric: True
          # é‡åŒ–ç²’åº¦ï¼šper_token, per_tensor
          granularity: per_token
          ste: True
          # é™æ€é‡åŒ–ï¼ˆæ ¡å‡†æœŸé—´çš„é‡åŒ–ï¼‰æˆ–åŠ¨æ€é‡åŒ–ï¼ˆæ¨ç†æœŸé—´çš„é‡åŒ–ï¼‰ã€‚
          static: True
      # è¿™éƒ¨åˆ†æ˜¯ä¸ºç‰¹å®šç®—æ³•è®¾è®¡çš„ï¼Œç”¨æˆ·å¯ä»¥å‚è€ƒæˆ‘ä»¬æä¾›çš„ç®—æ³•æ¥è®¾è®¡ä»–ä»¬è‡ªå·±çš„ç®—æ³•ã€‚
      special:
          let: True
          lwc_lr: 0.01
          let_lr: 0.005
          use_shift: False
          alpha: 0.5
          deactive_amp: True
          epochs: 20
          wd: 0
      # å¦‚æœ quant_out ä¸º Trueï¼Œä½¿ç”¨å‰ä¸€ä¸ªé‡åŒ–å—çš„è¾“å‡ºä½œä¸ºåç»­å—çš„æ ¡å‡†æ•°æ®ã€‚
      quant_out: True

  ```

## æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

âœ… [BLOOM](https://huggingface.co/bigscience/bloom)

âœ… [LLaMA](https://github.com/facebookresearch/llama)

âœ… [LLaMA V2](https://huggingface.co/meta-llama)

âœ… [StarCoder](https://github.com/bigcode-project/starcoder)

âœ… [OPT](https://huggingface.co/docs/transformers/model_doc/opt)

âœ… [Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)

âœ… [InternLM2](https://huggingface.co/internlm)

âœ… [Mistral](https://huggingface.co/docs/transformers/model_doc/mistral)

âœ… [LLaMA V3](https://huggingface.co/meta-llama)

âœ… [Mixtral](https://huggingface.co/docs/transformers/model_doc/mixtral)

âœ… [Qwen V2](https://github.com/QwenLM/Qwen2)

âœ… [LLaVA](https://github.com/haotian-liu/LLaVA)

âœ… [InternLM2.5](https://huggingface.co/internlm)

âœ… [StableLM](https://github.com/Stability-AI/StableLM)

âœ… [Gemma2](https://huggingface.co/docs/transformers/main/en/model_doc/gemma2)

âœ… [Phi2](https://huggingface.co/microsoft/phi-2)

âœ… [Phi 1.5](https://huggingface.co/microsoft/phi-1_5)

âœ… [MiniCPM](https://github.com/OpenBMB/MiniCPM)

âœ… [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)

ä½ å¯ä»¥å‚è€ƒ `llmc/models/*.py` ä¸‹çš„æ–‡ä»¶æ·»åŠ ä½ è‡ªå·±çš„æ¨¡å‹ç±»å‹ã€‚

## æ”¯æŒçš„ç®—æ³•åˆ—è¡¨

### é‡åŒ–

âœ… Naive

âœ… [AWQ](https://arxiv.org/abs/2306.00978)

âœ… [GPTQ](https://arxiv.org/abs/2210.17323)

âœ… [SmoothQuant](https://arxiv.org/abs/2211.10438)

âœ… [OS+](https://arxiv.org/abs/2304.09145)

âœ… [OmniQuant](https://arxiv.org/abs/2308.13137)

âœ… [NormTweaking](https://arxiv.org/abs/2309.02784)

âœ… [AdaDim](https://arxiv.org/pdf/2309.15531.pdf)

âœ… [QUIK](https://arxiv.org/abs/2310.09259)

âœ… [SpQR](https://arxiv.org/abs/2306.03078)

âœ… [DGQ](https://arxiv.org/abs/2310.04836)

âœ… [OWQ](https://arxiv.org/abs/2306.02272)

âœ… [LLM.int8()](https://arxiv.org/abs/2208.07339)

âœ… [HQQ](https://mobiusml.github.io/hqq_blog/)

âœ… [QuaRot](https://arxiv.org/abs/2404.00456)

### å‰ªæ

âœ… Naive(Magnitude)

âœ… [Wanda](https://arxiv.org/abs/2306.11695)

âœ… [ShortGPT](https://arxiv.org/abs/2403.03853)

## è‡´è°¢

æˆ‘ä»¬çš„ä»£ç å‚è€ƒäº†ä»¥ä¸‹ä»“åº“ï¼š

- https://github.com/mit-han-lab/llm-awq
- https://github.com/mit-han-lab/smoothquant
- https://github.com/OpenGVLab/OmniQuant
- https://github.com/IST-DASLab/gptq
- https://github.com/ModelTC/Outlier_Suppression_Plus
- https://github.com/IST-DASLab/QUIK
- https://github.com/Vahe1994/SpQR
- https://github.com/ilur98/DGQ
- https://github.com/xvyaward/owq
- https://github.com/TimDettmers/bitsandbytes
- https://github.com/mobiusml/hqq
- [https://github.com/locuslab/wanda](https://github.com/locuslab/wanda)
- [https://github.com/EleutherAI/lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)

## æ˜Ÿæ ‡å†å²

[![æ˜Ÿæ ‡å†å²å›¾è¡¨](https://api.star-history.com/svg?repos=ModelTC/llmc&type=Timeline)](https://star-history.com/#ModelTC/llmc&Timeline)

## å¼•ç”¨

å¦‚æœæ‚¨è®¤ä¸ºæˆ‘ä»¬çš„ LLM-QBench è®ºæ–‡/llmc å·¥å…·å¯¹æ‚¨çš„ç ”ç©¶æœ‰ç”¨æˆ–ç›¸å…³ï¼Œè¯·åŠ¡å¿…å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```
@misc{llmc,
   author = {llmc contributors},
   title = {llmc: Towards Accurate and Efficient LLM Compression},
   year = {2024},
   publisher = {GitHub},
   journal = {GitHub repository},
   howpublished = {\url{https://github.com/ModelTC/llmc}},
}

@misc{gong2024llmqbench,
      title={LLM-QBench: A Benchmark Towards the Best Practice for Post-training Quantization of Large Language Models},
      author={Ruihao Gong and Yang Yong and Shiqiao Gu and Yushi Huang and Yunchen Zhang and Xianglong Liu and Dacheng Tao},
      year={2024},
      eprint={2405.06001},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gong2024llmcbenchmarkinglargelanguage,
      title={LLMC: Benchmarking Large Language Model Quantization with a Versatile Compression Toolkit},
      author={Ruihao Gong and Yang Yong and Shiqiao Gu and Yushi Huang and Chentao Lv and Yunchen Zhang and Xianglong Liu and Dacheng Tao},
      year={2024},
      eprint={2405.06001},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.06001},
}
```
