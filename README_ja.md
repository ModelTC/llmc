# llmc: æ­£ç¢ºã§åŠ¹ç‡çš„ãªLLMåœ§ç¸®ã«å‘ã‘ã¦

<img src="./imgs/llmc.png" alt="llmc" style="zoom:35%;" />

[![ãƒ©ã‚¤ã‚»ãƒ³ã‚¹](https://img.shields.io/badge/ãƒ©ã‚¤ã‚»ãƒ³ã‚¹-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![arXiv](https://img.shields.io/badge/LLMC-2405.06001-b31b1b)](https://arxiv.org/abs/2405.06001)
[![GitHub ã‚¹ã‚¿ãƒ¼](https://img.shields.io/github/stars/ModelTC/llmc.svg?style=social&label=Star&maxAge=60)](https://github.com/ModelTC/llmc)
![è¨ªå•è€…](https://komarev.com/ghpvc/?username=llmc&label=visitors)
[![Discord ãƒãƒŠãƒ¼](https://img.shields.io/discord/1139835312592392214?logo=discord&logoColor=white)](https://discord.gg/qZKUDfhm)
[![QQ](https://img.shields.io/badge/QQ-EB1923?logo=tencent-qq&logoColor=white)](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=I9IGPWWj8uuRXWH3_ELWjouf6gkIMgUl&authKey=GA3WbFAsm90ePJf%2FCbc7ZyXXq4ShQktlBaLxgqS5yuSPAsr3%2BDKMRdosUiLYoilO&noverify=0&group_code=526192592)
[![Doc](https://img.shields.io/badge/docs-English-99cc2)](https://llmc-en.readthedocs.io/en/latest/)
[![Doc](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡-99cc2)](https://llmc-zhcn.readthedocs.io/en/latest/)

**\[ [English](README.md) | [ä¸­æ–‡](README_zh.md) | æ—¥æœ¬èª \]**

**llmc** ã¯ã€æœ€å…ˆç«¯ã®åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ´»ç”¨ã—ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æãªã†ã“ã¨ãªãåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã€ã‚ªãƒ•ãƒ»ã‚¶ãƒ»ã‚·ã‚§ãƒ«ãƒ•ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

**è‹±èªã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**ã¯[ã“ã¡ã‚‰](https://llmc-en.readthedocs.io/en/latest/)ã§ã™ã€‚

**docker hub**ã¯[ã“ã¡ã‚‰](https://hub.docker.com/r/llmcompression/llmc)ã§ã™ã€‚

**ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**:

- [Discord ã‚µãƒ¼ãƒãƒ¼](https://discord.gg/qZKUDfhm)
- [Tencent QQ ã‚°ãƒ«ãƒ¼ãƒ—](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=I9IGPWWj8uuRXWH3_ELWjouf6gkIMgUl&authKey=GA3WbFAsm90ePJf%2FCbc7ZyXXq4ShQktlBaLxgqS5yuSPAsr3%2BDKMRdosUiLYoilO&noverify=0&group_code=526192592)

## ãƒ‹ãƒ¥ãƒ¼ã‚¹

- **2024å¹´9æœˆ9æ—¥:** ğŸ”¥ é‡å­åŒ–ã•ã‚ŒãŸ LLM ã® [vLLM](https://github.com/vllm-project/vllm) ã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã—ã¾ã—ãŸ ([ã“ã¡ã‚‰](https://llmc-en.readthedocs.io/en/latest/backend/vllm.html) ã‚’å‚ç…§)ã€‚ã•ã‚‰ã«ã€å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å‘ã‘ãŸ ãƒ™ã‚¹ãƒˆ ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®æ§‹æˆ ã‚‚ã„ãã¤ã‹æä¾›ã—ã¦ã„ã¾ã™ (ãƒ™ã‚¹ãƒˆ ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ [ã“ã¡ã‚‰](https://llmc-en.readthedocs.io/en/latest/) ã‚’å‚ç…§)ã€‚

* **2024å¹´9æœˆ3æ—¥:** ğŸš€ ç§ãŸã¡ã¯OpenCompassã®ç²¾åº¦è©•ä¾¡ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã—ãŸã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯[ã“ã¡ã‚‰](https://llmc-en.readthedocs.io/en/latest/advanced/model_test_v2.html)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ãœã²ã”åˆ©ç”¨ãã ã•ã„ï¼

* **2024å¹´8æœˆ22æ—¥ï¼š** ğŸ”¥ç§ãŸã¡ã¯ã€ç¾åœ¨ã®æœ€å…ˆç«¯æŠ€è¡“ã§ã‚ã‚‹[SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)ï¼ˆ[ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ](#supported-model-list)ã‚’å‚ç…§ï¼‰ã‚’å«ã‚€å¤šãã®å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€æ”¹è‰¯ã•ã‚ŒãŸ[lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) ğŸ¤— ã‚’é€šã˜ã¦ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¿ã‚¹ã‚¯ã®è©•ä¾¡ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã¾ãš `save_trans` ãƒ¢ãƒ¼ãƒ‰ï¼ˆ[è¨­å®š](#è¨­å®š)ã® `save` éƒ¨åˆ†ã‚’å‚ç…§ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å¤‰æ›´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä¿å­˜ã—ã¾ã™ã€‚å¤‰æ›å¾Œã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ãŸå¾Œã€[run_lm_eval.sh](scripts/run_lm_eval.sh)ã‚’å‚ç…§ã—ã¦é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚è©³ç´°ã¯[ã“ã¡ã‚‰](https://llmc-en.readthedocs.io/en/latest/advanced/model_test.html)ã§ç¢ºèªã§ãã¾ã™ã€‚

* **2024å¹´7æœˆ23æ—¥:** ğŸºğŸºğŸº æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ãƒšãƒ¼ãƒ‘ãƒ¼ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã™:

  [**LLMC: å¤šç”¨é€”ã®åœ§ç¸®ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é‡å­åŒ–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**](https://arxiv.org/abs/2405.06001v2)ã€‚

  [Ruihao Gong\*](https://xhplus.github.io/)ã€[Yang Yong\*](https://github.com/helloyongyang)ã€[Shiqiao Gu\*](https://github.com/gushiqiao)ã€[Yushi Huang\*](https://github.com/Harahan)ã€[Chengtao Lv](https://scholar.google.com/citations?user=r8vseSUAAAAJ&hl=en)ã€[Yunchen Zhang](https://scholar.google.com/citations?user=glkWFyUAAAAJ&hl=en)ã€[Xianglong LiuğŸ“§](https://xlliu-beihang.github.io/)ã€[Dacheng Tao](https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=en)

  (\* ã¯åŒç­‰ã®è²¢çŒ®ã€ğŸ“§ ã¯å¯¾å¿œã™ã‚‹è²¢çŒ®ã‚’è¡¨ã—ã¾ã™è‘—è€…ã€‚)

  <div align=center>
  <img src="./imgs/K.png" alt="comp" width="800" />
  </div>

  ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã®ã§ã¯ãªãã€ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è€ƒæ…®ã—ã¦ã€LLMé‡å­åŒ–ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¼ã‹ã¤å…¬å¹³ã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã¾ã™ã€‚è©³ç´°ãªè¦³å¯Ÿã¨åˆ†æã«ã‚ˆã‚Šã€ã•ã¾ã–ã¾ãªæ§‹æˆã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨æ–¹æ³•ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ã•ã¾ã–ã¾ãªã‚¿ã‚¤ãƒ—ã®æ–°ã—ã„ãƒã‚¤ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆLLMCã¨åŒ…æ‹¬çš„ãªæ´å¯Ÿã«ã‚ˆã‚Šã€å°†æ¥ã®LLMç ”ç©¶è€…ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«é©ã—ãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ä½ãƒ“ãƒƒãƒˆå½¢å¼ã‚’åŠ¹ç‡çš„ã«çµ±åˆã—ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®åœ§ç¸®ã‚’æ°‘ä¸»åŒ–ã§ãã¾ã™ã€‚

* **2024å¹´7æœˆ16æ—¥:** ğŸ”¥ç¾åœ¨ã€llmã®ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ã¨å±¤é–“æ··åˆãƒ“ãƒƒãƒˆé‡å­åŒ–ã®ãŸã‚ã®Wanda/Naive(Magnitude)ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼

* **2024å¹´7æœˆ14æ—¥:** ğŸ”¥ç¾åœ¨ã€å›è»¢ãƒ™ãƒ¼ã‚¹ã®é‡å­åŒ–QuaRotã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼

* **2024å¹´7æœˆ4æ—¥:** ğŸ“± ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ãƒãƒ£ãƒ³ãƒãƒ«ã‚’é–‹è¨­ã—ã¾ã—ãŸã€‚è³ªå•ãŒã‚ã‚‹å ´åˆã¯ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ ã—ã¦ãã ã•ã„:

  - [Discord ã‚µãƒ¼ãƒãƒ¼](https://discord.gg/qZKUDfhm)
  - [Tencent QQ ã‚°ãƒ«ãƒ¼ãƒ—](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=I9IGPWWj8uuRXWH3_ELWjouf6gkIMgkUl&authKey=GA3WbFAsm90ePJf%2FCbc7ZyXXq4ShQktlBaLxgqS5yuSPAsr3%2BDKMRdosUiLYoilO&noverify=0&group_code=526192592)

* **2024å¹´5æœˆ17æ—¥:** ğŸš€ ç¾åœ¨ã€LLaVAã€Mixtralã€LLaMA V3ã€Qwen V2ãªã©ã®é«˜åº¦ãªå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼

* **2024å¹´5æœˆ13æ—¥:** ğŸºğŸºğŸº é‡å­åŒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è«–æ–‡ã‚’ç™ºè¡¨ã—ã¾ã—ãŸ:

  [**LLM-QBench: å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é‡å­åŒ–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å‘ã‘ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**](https://arxiv.org/abs/2405.06001).

  [Ruihao Gong\*](https://xhplus.github.io/), [Yang Yong\*](https://github.com/helloyongyang), [Shiqiao Gu\*](https://github.com/gushiqiao), [Yushi Huang\*](https://github.com/Harahan), [Yunchen Zhang](https://scholar.google.com/citations?user=glkWFyUAAAAJ&hl=en), [Xianglong LiuğŸ“§](https://xlliu-beihang.github.io/), [Dacheng Tao](https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=en)

  (\* ã¯åŒç­‰ã®è²¢çŒ®ã‚’ç¤ºã—ã€ğŸ“§ ã¯å¯¾å¿œã™ã‚‹è‘—è€…ã‚’ç¤ºã—ã¾ã™ã€‚)

  <div align=center>
   <img src="./imgs/best_practice.png" alt="comp" width="800" />
  </div>

  æ ¡æ­£ã‚³ã‚¹ãƒˆã€æ¨è«–åŠ¹ç‡ã€ãŠã‚ˆã³é‡å­åŒ–ç²¾åº¦ã‚’è€ƒæ…®ã—ã¦ã€é‡å­åŒ–æŠ€è¡“ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã—ã€å…¬å¹³ã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã¾ã—ãŸã€‚å¤šæ§˜ãªãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ç´„600ã®å®Ÿé¨“ãŒã€æ ¡æ­£ãƒ‡ãƒ¼ã‚¿ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ãŠã‚ˆã³é‡å­åŒ–æ§‹æˆã®é¸æŠã«é–¢ã™ã‚‹3ã¤ã®æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ´å¯Ÿã«åŸºã¥ã„ã¦ã€LLM PTQãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãŒè¨­è¨ˆã•ã‚Œã€ã•ã¾ã–ã¾ãªã‚·ãƒŠãƒªã‚ªã§æœ€é«˜ã®ç²¾åº¦ã¨åŠ¹ç‡ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

* **2024å¹´3æœˆ7æ—¥:** ğŸš€ å¼·åŠ›ã§åŠ¹ç‡çš„ãªLLMåœ§ç¸®ãƒ„ãƒ¼ãƒ«ã®é‡å­åŒ–éƒ¨åˆ†ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚æ³¨ç›®ã™ã¹ãã¯ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è«–æ–‡ãŒè¿‘æ—¥å…¬é–‹äºˆå®šã§ã™ğŸ˜Šã€‚

## ãƒã‚¤ãƒ©ã‚¤ãƒˆæ©Ÿèƒ½

- LLMsï¼ˆä¾‹ï¼šLlama2-70Bã€OPT-175Bï¼‰ã‚’é‡å­åŒ–ã—ã€1ã¤ã®A100/H100/H800 GPUã§PPLã‚’è©•ä¾¡ã—ã¾ã™ğŸ’¥ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã§ãã‚‹æœ€å…ˆç«¯ã®åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒ[å…ƒã®ãƒªãƒã‚¸ãƒˆãƒªã¨ä¸€è‡´](benchmark/align.md)ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯1ã¤ã®LLMã§è¤‡æ•°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é †æ¬¡ä½¿ç”¨ã§ãã¾ã™ğŸ’¥ã€‚
- ç‰¹å®šã®åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒ„ãƒ¼ãƒ«ã«ã‚ˆã£ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸå¤‰æ›ãƒ¢ãƒ‡ãƒ«ï¼ˆ[æ§‹æˆ](#æ§‹æˆ)ã®`quant`éƒ¨åˆ†ã®`save_trans`ãƒ¢ãƒ¼ãƒ‰ï¼‰ã¯ã€è¤‡æ•°ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆä¾‹ï¼š[Lightllm](https://github.com/ModelTC/lightllm)ã€[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)ï¼‰ã«ã‚ˆã£ã¦å˜ç´”ãªé‡å­åŒ–ã‚’è¡Œã„ã€ç‰¹å®šã®åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã§ãã¾ã™ã€‚å¯¾å¿œã™ã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒæ¨è«–ã§ãã¾ã™ğŸ’¥ã€‚
- æµ…ã„ãƒ¡ãƒ¢ãƒªãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆã‚’æŒã¤åœ§ç¸®ãƒ¢ãƒ‡ãƒ«ï¼ˆ[æ§‹æˆ](#æ§‹æˆ)ã®`quant`éƒ¨åˆ†ã®`save_lightllm`ãƒ¢ãƒ¼ãƒ‰ï¼‰ã¯ã€[Lightllm](https://github.com/ModelTC/lightllm)ã«ã‚ˆã£ã¦ç›´æ¥æ¨è«–ã§ãã¾ã™ğŸ’¥ã€‚

## ä½¿ç”¨æ–¹æ³•

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

   ```shell
   # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
   cd llmc
   pip install -r requirements.txt
   ```

2. ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™ã€‚

   ```shell
   # huggingfaceã‹ã‚‰LLMã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸå¾Œã€æ¬¡ã®ã‚ˆã†ã«æ ¡æ­£ãƒ‡ãƒ¼ã‚¿ã¨è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™ï¼š
   cd tools
   python download_calib_dataset.py --save_path [æ ¡æ­£ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹]
   python download_eval_dataset.py --save_path [è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹]
   ```

3. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é¸æŠã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã—ã¾ã™ï¼š

   ```shell
   # ã“ã‚Œã¯Awqã«é–¢ã™ã‚‹ä¾‹ã§ã™ï¼š
   cd scripts
   # bashãƒ•ã‚¡ã‚¤ãƒ«å†…ã®llmcã®ãƒ‘ã‚¹``llmc_path``ã‚’å¤‰æ›´ã—ã¾ã™ã€‚``llmc/configs/quantization/Awq/``ã«é…ç½®ã•ã‚ŒãŸæ§‹æˆã®1ã¤ã‚’é¸æŠã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã™ã‚‹ã‹ã€run_awq_llama.shã®``--config``å¼•æ•°ã‚’å¤‰æ›´ã—ã¦æä¾›ã•ã‚ŒãŸæ§‹æˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
   bash run_awq_llama.sh
   ```

## æ§‹æˆ

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ§‹æˆã‚’è¨­è¨ˆã™ã‚‹ã®ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã«ã€`llmc/configs/`ã®ä¸‹ã«æä¾›ã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®æ§‹æˆã®ã„ãã¤ã‹ã®ä¸€èˆ¬çš„ãªæ§‹æˆã‚’èª¬æ˜ã—ã¾ã™ï¼š

- `model`:

  ```yaml
  model:
      # ``llmc/models/*.py``ã®ã‚¯ãƒ©ã‚¹åã«ç½®ãæ›ãˆã¾ã™ã€‚
      type: Llama
      # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã«ç½®ãæ›ãˆã¾ã™ã€‚
      path: model path
      torch_dtype: auto
  ```

- `calib`:

  ```yaml
  # æ³¨æ„ï¼šä¸€éƒ¨ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¯``calib``ãŒå¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚ä¾‹ï¼šnaive... ã—ãŸãŒã£ã¦ã€ã“ã®éƒ¨åˆ†ã‚’å‰Šé™¤ã§ãã¾ã™ã€‚
  calib:
      # ä»¥å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸæ ¡æ­£ãƒ‡ãƒ¼ã‚¿åã«ç½®ãæ›ãˆã¾ã™ã€‚ä¾‹ï¼špilevalã€c4ã€wikitext2ã€ã¾ãŸã¯ptbã€‚
      name: pileval
      download: False
      # ä»¥å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸæ ¡æ­£ãƒ‡ãƒ¼ã‚¿ã®1ã¤ã®ãƒ‘ã‚¹ã«ç½®ãæ›ãˆã¾ã™ã€‚ä¾‹ï¼špilevalã€c4ã€wikitext2ã€ã¾ãŸã¯ptbã€‚
      path: calib data path
      n_samples: 128
      bs: -1
      seq_len: 512
      # ``llmc/data/dataset/specified_preproc.py``ã®é–¢æ•°åã«ç½®ãæ›ãˆã¾ã™ã€‚
      preproc: general
      seed: *seed
  ```

- `eval`:

  ```yaml
  # äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/å¤‰æ›/å½é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®PPLã‚’è©•ä¾¡ã—ãŸã„å ´åˆã€‚
  eval:
      # äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€å¤‰æ›ã€å½é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€è©•ä¾¡ã—ãŸã„ä½ç½®ã‚’è¨­å®šã§ãã¾ã™ã€‚
      eval_pos: [pretrain, transformed, fake_quant]
      # ä»¥å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®åå‰ã«ç½®ãæ›ãˆã¾ã™ã€‚ä¾‹ï¼šc4ã€wikitext2ã€ptbã€ã¾ãŸã¯[c4, wikitext2]ã€‚
      name: wikitext2
      download: False
      path: eval data path
      # 70Bãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®å ´åˆã€bsã‚’20ã«è¨­å®šã—ã€inference_per_blockã‚’Trueã«è¨­å®šã§ãã¾ã™ã€‚
      # 7B / 13Bãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®å ´åˆã€bsã‚’1ã«è¨­å®šã—ã€inference_per_blockã‚’Falseã«è¨­å®šã§ãã¾ã™ã€‚
      bs: 1
      inference_per_block: False
      seq_len: 2048
  ```

- `save`:

  ```yaml
  save:
      # ``save_trans``ãŒTrueã®å ´åˆã€å¤‰æ›ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨æ§‹é€ ã¯å…ƒã®ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã§ã‚ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å˜ç´”ãªé‡å­åŒ–ã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹å®šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
      save_trans: False
      # ``save_lightllm``ã¾ãŸã¯ ``save_trtllm`` ãŒTrueã®å ´åˆã€å®Ÿéš›ã®é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹ï¼šä½ãƒ“ãƒƒãƒˆã®é‡ã¿ã¨é‡ã¿ãŠã‚ˆã³ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®é‡å­åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚
      save_lightllm: False
      # ``save_fake``ãŒTrueã®å ´åˆã€å½é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹ï¼šé‡å­åŒ–è§£é™¤ã•ã‚ŒãŸé‡ã¿ã¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®é‡å­åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚
      save_fake: False
      save_path: ./save
  ```

- `quant`:

  ```yaml
  quant:
      # ``llmc/compression/quantization/*.py``ã®ã‚¯ãƒ©ã‚¹åã«ç½®ãæ›ãˆã¾ã™ã€‚
      method: OmniQuant
      # é‡ã¿ã®ã¿ã®é‡å­åŒ–ã«ã¯``act``éƒ¨åˆ†ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
      weight:
          bit: 8
          symmetric: True
          # é‡å­åŒ–ã®ç²’åº¦ï¼šper_channelã€per_tensorã€per_headï¼ˆæ¨å¥¨ã•ã‚Œã¾ã›ã‚“ï¼‰ã€‚
          granularity: per_channel
          group_size: -1
          # æ ¡æ­£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼šlearnbleã€mseã€ãŠã‚ˆã³minmaxï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã€‚
          calib_algo: learnable
          # ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆã‚¹ãƒ«ãƒ¼æ¨å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€å­¦ç¿’å¯èƒ½ãªæ ¡æ­£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«å¿…è¦ã§ã™ã€‚
          ste: True
      act:
          bit: 8
          symmetric: True
          # é‡å­åŒ–ã®ç²’åº¦ï¼šper_tokenã€per_tensor
          granularity: per_token
          ste: True
          # é™çš„é‡å­åŒ–ï¼ˆæ ¡æ­£ä¸­ã®é‡å­åŒ–ï¼‰ã¾ãŸã¯å‹•çš„é‡å­åŒ–ï¼ˆæ¨è«–ä¸­ã®é‡å­åŒ–ï¼‰ã€‚
          static: True
      # ã“ã®éƒ¨åˆ†ã¯ç‰¹å®šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ç”¨ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€æä¾›ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’å‚è€ƒã«ã—ã¦ç‹¬è‡ªã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è¨­è¨ˆã§ãã¾ã™ã€‚
      special:
          let: True
          lwc_lr: 0.01
          let_lr: 0.005
          use_shift: False
          alpha: 0.5
          deactive_amp: True
          epochs: 20
          wd: 0
      # quant_outãŒTrueã®å ´åˆã€å‰ã®é‡å­åŒ–ãƒ–ãƒ­ãƒƒã‚¯ã®å‡ºåŠ›ã‚’æ¬¡ã®ãƒ–ãƒ­ãƒƒã‚¯ã®æ ¡æ­£ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚
      quant_out: True
  ```

## ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ

âœ… [BLOOM](https://huggingface.co/bigscience/bloom)

âœ… [LLaMA](https://github.com/facebookresearch/llama)

âœ… [LLaMA V2](https://huggingface.co/meta-llama)

âœ… [StarCoder](https://github.com/bigcode-project/starcoder)

âœ… [OPT](https://huggingface.co/docs/transformers/model_doc/opt)

âœ… [Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)

âœ… [InternLM2](https://huggingface.co/internlm)

âœ… [Mistral](https://huggingface.co/docs/transformers/model_doc/mistral)

âœ… [LLaMA V3](https://huggingface.co/meta-llama)

âœ… [Mixtral](https://huggingface.co/docs/transformers/model_doc/mixtral)

âœ… [Qwen V2](https://github.com/QwenLM/Qwen2)

âœ… [LLaVA](https://github.com/haotian-liu/LLaVA)

âœ… [Mixtral](https://huggingface.co/docs/transformers/model_doc/mixtral)

âœ… [Qwen V2](https://github.com/QwenLM/Qwen2)

âœ… [LLaVA](https://github.com/haotian-liu/LLaVA)

âœ… [InternLM2.5](https://huggingface.co/internlm)

âœ… [StableLM](https://github.com/Stability-AI/StableLM)

âœ… [Gemma2](https://huggingface.co/docs/transformers/main/en/model_doc/gemma2)

âœ… [Phi2](https://huggingface.co/microsoft/phi-2)

âœ… [Phi 1.5](https://huggingface.co/microsoft/phi-1_5)

âœ… [MiniCPM](https://github.com/OpenBMB/MiniCPM)

âœ… [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)

`llmc/models/*.py`ã®ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ã€ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’è¿½åŠ ã§ãã¾ã™ã€‚

## ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒªã‚¹ãƒˆ

### é‡å­åŒ–

âœ… Naive

âœ… [AWQ](https://arxiv.org/abs/2306.00978)

âœ… [GPTQ](https://arxiv.org/abs/2210.17323)

âœ… [SmoothQuant](https://arxiv.org/abs/2211.10438)

âœ… [OS+](https://arxiv.org/abs/2304.09145)

âœ… [OmniQuant](https://arxiv.org/abs/2308.13137)

âœ… [NormTweaking](https://arxiv.org/abs/2309.02784)

âœ… [AdaDim](https://arxiv.org/pdf/2309.15531.pdf)

âœ… [QUIK](https://arxiv.org/abs/2310.09259)

âœ… [SpQR](https://arxiv.org/abs/2306.03078)

âœ… [DGQ](https://arxiv.org/abs/2310.04836)

âœ… [OWQ](https://arxiv.org/abs/2306.02272)

âœ… [LLM.int8()](https://arxiv.org/abs/2208.07339)

âœ… [HQQ](https://mobiusml.github.io/hqq_blog/)

âœ… [QuaRot](https://arxiv.org/abs/2404.00456)

### å‰ªå®š

âœ… Naive(Magnitude)

âœ… [Wanda](https://arxiv.org/abs/2306.11695)

âœ… [ShortGPT](https://arxiv.org/abs/2403.03853)

## è¬è¾

ä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å‚è€ƒã«ã—ã¦ã‚³ãƒ¼ãƒ‰ã‚’é–‹ç™ºã—ã¾ã—ãŸï¼š

- https://github.com/mit-han-lab/llm-awq
- https://github.com/mit-han-lab/smoothquant
- https://github.com/OpenGVLab/OmniQuant
- https://github.com/IST-DASLab/gptq
- https://github.com/ModelTC/Outlier_Suppression_Plus
- https://github.com/IST-DASLab/QUIK
- https://github.com/Vahe1994/SpQR
- https://github.com/ilur98/DGQ
- https://github.com/xvyaward/owq
- https://github.com/TimDettmers/bitsandbytes
- https://github.com/mobiusml/hqq
- [https://github.com/spcl/QuaRot](https://github.com/spcl/QuaRot)
- [https://github.com/locuslab/wanda](https://github.com/locuslab/wanda)
- [https://github.com/EleutherAI/lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)

## ã‚¹ã‚¿ãƒ¼å±¥æ­´

[![ã‚¹ã‚¿ãƒ¼å±¥æ­´ãƒãƒ£ãƒ¼ãƒˆ](https://api.star-history.com/svg?repos=ModelTC/llmc&type=Timeline)](https://star-history.com/#ModelTC/llmc&Timeline)

## å¼•ç”¨

LLM-QBenchè«–æ–‡/llmcãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆãŒç ”ç©¶ã«å½¹ç«‹ã¤ã¾ãŸã¯é–¢é€£ã—ã¦ã„ã‚‹å ´åˆã¯ã€è«–æ–‡ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š

```
@misc{llmc,
   author = {llmc contributors},
   title = {llmc: Towards Accurate and Efficient LLM Compression},
   year = {2024},
   publisher = {GitHub},
   journal = {GitHub repository},
   howpublished = {\url{https://github.com/ModelTC/llmc}},
}

@misc{gong2024llmqbench,
      title={LLM-QBench: A Benchmark Towards the Best Practice for Post-training Quantization of Large Language Models},
      author={Ruihao Gong and Yang Yong and Shiqiao Gu and Yushi Huang and Yunchen Zhang and Xianglong Liu and Dacheng Tao},
      year={2024},
      eprint={2405.06001},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gong2024llmcbenchmarkinglargelanguage,
      title={LLMC: Benchmarking Large Language Model Quantization with a Versatile Compression Toolkit},
      author={Ruihao Gong and Yang Yong and Shiqiao Gu and Yushi Huang and Chentao Lv and Yunchen Zhang and Xianglong Liu and Dacheng Tao},
      year={2024},
      eprint={2405.06001},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.06001},
}
```
